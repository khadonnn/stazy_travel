import json
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import os
import numpy as np

# ---------------------------------------------------------
# 1. Cáº¤U HÃŒNH & TRá»ŒNG Sá»
# ---------------------------------------------------------
INPUT_FILE = "jsons/__interactions.json"
OUTPUT_FILE = "jsons/__recommendations.json"

# Trá»ng sá»‘ Implicit Feedback (Khá»›p vá»›i luáº­n vÄƒn & data sinh ra)
WEIGHT_MAP = {
    "VIEW": 1.0,            # Xem: Thá»ƒ hiá»‡n sá»± tÃ² mÃ² nháº¹
    "LIKE": 3.0,            # ThÃ­ch: Quan tÃ¢m rÃµ rÃ ng
    "CLICK_BOOK_NOW": 4.0,  # Intent cao
    "BOOK": 5.0,            # Conversion: TÆ°Æ¡ng tÃ¡c máº¡nh nháº¥t
    "SEARCH_QUERY": 0.5,    # (Náº¿u cÃ³)
    "share": 2.0,           # (Náº¿u cÃ³)
    "CANCEL": -5.0          # (Náº¿u cÃ³) - Pháº¡t náº·ng
}

def load_data():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {INPUT_FILE}. HÃ£y cháº¡y generate_interactions.py trÆ°á»›c.")
        return None
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def get_popular_items(df, top_n=5):
    """
    HÃ m Fallback: Láº¥y ra danh sÃ¡ch cÃ¡c khÃ¡ch sáº¡n phá»• biáº¿n nháº¥t (dá»±a trÃªn tá»•ng trá»ng sá»‘ interaction)
    DÃ¹ng cho trÆ°á»ng há»£p User má»›i hoáº·c User cÃ³ hÃ nh vi quÃ¡ dá»‹ biá»‡t.
    """
    popular_items = df.groupby('hotelId')['weight'].sum().sort_values(ascending=False).head(top_n)
    ids = popular_items.index.tolist()
    # Score giáº£ láº­p cho items phá»• biáº¿n (tá»« 0.5 -> 0.4) Ä‘á»ƒ phÃ¢n biá»‡t vá»›i items Ä‘Æ°á»£c personalize
    scores = {str(hid): round(0.5 - (i * 0.02), 2) for i, hid in enumerate(ids)}
    return ids, scores

def main():
    print("â³ Äang xá»­ lÃ½ Recommendation Engine...")
    
    data = load_data()
    if not data: return

    # 1. Táº¡o DataFrame & Tiá»n xá»­ lÃ½
    df = pd.DataFrame(data)
    
    # Lá»c bá» interaction khÃ´ng há»£p lá»‡
    original_len = len(df)
    df = df[df['hotelId'].notna()] # Bá» dÃ²ng khÃ´ng cÃ³ hotelId
    
    # TÃ­nh Ä‘iá»ƒm trá»ng sá»‘
    df['weight'] = df['type'].map(WEIGHT_MAP).fillna(1.0)
    
    print(f"ğŸ“Š Dá»¯ liá»‡u Ä‘áº§u vÃ o: {len(df)} interactions há»£p lá»‡.")

    # 2. XÃ¢y dá»±ng User-Item Matrix
    # index=UserId, columns=HotelId, values=Sum(Weight)
    user_item_matrix = df.pivot_table(index='userId', columns='hotelId', values='weight', aggfunc='sum').fillna(0)
    
    print(f"ğŸ“ KÃ­ch thÆ°á»›c ma tráº­n: {user_item_matrix.shape} (Users x Hotels)")

    # 3. TÃ­nh Cosine Similarity (User-User)
    # Chá»‰ tÃ­nh khi ma tráº­n Ä‘á»§ lá»›n
    if user_item_matrix.shape[0] > 1:
        user_similarity = cosine_similarity(user_item_matrix)
        user_sim_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)
    else:
        print("âš ï¸ KhÃ´ng Ä‘á»§ user Ä‘á»ƒ tÃ­nh tÆ°Æ¡ng Ä‘á»“ng. Sáº½ dÃ¹ng fallback toÃ n bá»™.")
        user_sim_df = pd.DataFrame()

    # Chuáº©n bá»‹ danh sÃ¡ch fallback (Top Popular)
    popular_ids, popular_scores = get_popular_items(df)

    # 4. HÃ m táº¡o gá»£i Ã½ cÃ¡ nhÃ¢n hÃ³a
    def generate_user_recs(user_id, k_neighbors=10, top_n=5):
        # TrÆ°á»ng há»£p 1: User chÆ°a cÃ³ trong ma tráº­n (Cold Start) -> Tráº£ vá» Popular
        if user_id not in user_item_matrix.index:
            return popular_ids, popular_scores

        # TrÆ°á»ng há»£p 2: CÃ³ lá»‹ch sá»­ -> DÃ¹ng Collaborative Filtering
        # Láº¥y K user giá»‘ng nháº¥t (bá» qua chÃ­nh mÃ¬nh á»Ÿ index 0 vÃ¬ sim=1.0)
        if user_id not in user_sim_df.index:
             return popular_ids, popular_scores
             
        sim_users = user_sim_df[user_id].sort_values(ascending=False).iloc[1:k_neighbors+1]
        
        # Dictionary lÆ°u tá»•ng Ä‘iá»ƒm dá»± Ä‘oÃ¡n: { hotel_id: total_score }
        item_scores = {}
        # Dictionary lÆ°u tá»•ng Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng (Ä‘á»ƒ chuáº©n hÃ³a): { hotel_id: sum_similarity }
        sim_sums = {}

        for neighbor_id, similarity in sim_users.items():
            if similarity <= 0: continue # Bá» qua náº¿u khÃ´ng giá»‘ng hoáº·c Ä‘á»‘i nghá»‹ch

            # Láº¥y cÃ¡c item mÃ  hÃ ng xÃ³m Ä‘Ã£ tÆ°Æ¡ng tÃ¡c (weight > 0)
            neighbor_ratings = user_item_matrix.loc[neighbor_id]
            rated_items = neighbor_ratings[neighbor_ratings > 0].index
            
            for item_id in rated_items:
                # Chá»‰ gá»£i Ã½ item mÃ  user hiá»‡n táº¡i CHÆ¯A xem/mua (weight == 0)
                if user_item_matrix.loc[user_id, item_id] == 0:
                    # Dá»± Ä‘oÃ¡n = Similarity * Rating cá»§a hÃ ng xÃ³m
                    item_scores[item_id] = item_scores.get(item_id, 0) + (similarity * neighbor_ratings[item_id])
                    sim_sums[item_id] = sim_sums.get(item_id, 0) + similarity

        if not item_scores:
            return popular_ids, popular_scores # Fallback náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c gá»£i Ã½ nÃ o tá»« hÃ ng xÃ³m

        # TÃ­nh Ä‘iá»ƒm trung bÃ¬nh cÃ³ trá»ng sá»‘ & Sort
        final_scores = []
        for item_id, score_sum in item_scores.items():
            # Normalize: Chia cho tá»•ng Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng Ä‘á»ƒ score vá» thang Ä‘iá»ƒm gá»‘c (gáº§n Ä‘Ãºng)
            normalized_score = score_sum / sim_sums[item_id] if sim_sums[item_id] > 0 else 0
            final_scores.append((item_id, normalized_score))
        
        # Sort giáº£m dáº§n
        final_scores.sort(key=lambda x: x[1], reverse=True)
        top_recs = final_scores[:top_n]

        # Format output
        rec_ids = []
        rec_scores_map = {}
        
        if top_recs:
            # Láº¥y Ä‘iá»ƒm cao nháº¥t trong danh sÃ¡ch gá»£i Ã½ nÃ y lÃ m chuáº©n (100%)
            max_pred = top_recs[0][1] 
            
            for pid, pscore in top_recs:
                # Logic chuáº©n hÃ³a tÆ°Æ¡ng Ä‘á»‘i (Relative Normalization):
                # Item cao nháº¥t sáº½ cÃ³ ratio = 1.0. Item tháº¥p hÆ¡n sáº½ < 1.0.
                ratio = pscore / max_pred if max_pred > 0 else 0
                
                # Scale vá» khoáº£ng 60% -> 99% Ä‘á»ƒ hiá»ƒn thá»‹ lÃªn UI cho Ä‘áº¹p
                # CÃ´ng thá»©c: 0.6 + (ratio * 0.39)
                display_score = round(0.60 + (ratio * 0.39), 2)
                
                rec_ids.append(int(pid))
                rec_scores_map[str(pid)] = display_score

        return rec_ids, rec_scores_map

    # 5. Cháº¡y Loop cho táº¥t cáº£ User (ká»ƒ cáº£ nhá»¯ng user cÃ³ trong User List mÃ  chÆ°a cÃ³ interaction)
    # Äá»ƒ Ä‘áº£m báº£o Ä‘áº§y Ä‘á»§, ta nÃªn láº¥y list user gá»‘c tá»« file User (náº¿u cÃ³), á»Ÿ Ä‘Ã¢y ta láº¥y tá»« matrix index
    recommendations_export = []
    
    # Láº¥y danh sÃ¡ch user duy nháº¥t tá»« interaction
    all_users = df['userId'].unique()
    
    count = 0
    for uid in all_users:
        ids, scores = generate_user_recs(uid)
        
        recommendations_export.append({
            "userId": uid,
            "hotelIds": ids,
            "score": scores
        })
        count += 1

    # 6. Xuáº¥t file
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(recommendations_export, f, ensure_ascii=False, indent=2)

    print(f"âœ… HoÃ n táº¥t! ÄÃ£ táº¡o gá»£i Ã½ cho {count} users.")
    print(f"ğŸ’¾ File lÆ°u táº¡i: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()